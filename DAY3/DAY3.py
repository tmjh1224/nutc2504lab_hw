import time
import requests
import os
import operator
from typing import Annotated, TypedDict
from langgraph.graph import StateGraph, START, END
from langchain_openai import ChatOpenAI

class State(TypedDict):
    audio_path: str
    raw_txt: str
    raw_srt: str
    minutes: str
    summary: str
    final_report: str

# --- 2. åˆå§‹åŒ– LLM ---
llm = ChatOpenAI(
    base_url="https://ws-02.wade0426.me/v1",
    api_key="YOUR_API_KEY", 
    model="google/gemma-3-27b-it",
    temperature=0
)

# --- 3. å®šç¾© Nodes ---

def asr_node(state: State):
    print(f"--- [Node 1] ASR è½‰éŒ„ä¸­... (æª”æ¡ˆ: {state['audio_path']}) ---")
    BASE = "https://3090api.huannago.com"
    CREATE_URL = f"{BASE}/api/v1/subtitle/tasks"
    auth = ("nutc2504", "nutc2504")
    
    with open(state["audio_path"], "rb") as f:
        files = {"audio": (os.path.basename(state['audio_path']), f, "audio/wav")}
        r = requests.post(CREATE_URL, files=files, timeout=60, auth=auth)
    
    r.raise_for_status()
    task_id = r.json()["id"]
    print(f"ä»»å‹™å»ºç«‹æˆåŠŸ ID: {task_id}")
    
    def wait_download(url_type: str):
        url = f"{BASE}/api/v1/subtitle/tasks/{task_id}/subtitle?type={url_type}"
        while True:
            res = requests.get(url, auth=auth)
            if res.status_code == 200 and len(res.text.strip()) > 0:
                return res.text
            time.sleep(3) # ASR è½‰éŒ„éœ€è¦æ™‚é–“ï¼Œæ¯ 3 ç§’æª¢æŸ¥ä¸€æ¬¡

    # å–å¾—åŸå§‹è³‡æ–™
    txt = wait_download("TXT")
    srt = wait_download("SRT")
    print("ASR è½‰éŒ„å®Œæˆ")
    return {"raw_txt": txt, "raw_srt": srt}

def minutes_taker_node(state: State):
    print("--- [Node 2-A] æ­£åœ¨æ•´ç†é€å­—ç¨¿... ---")
    prompt = f"è«‹æ ¹æ“šä»¥ä¸‹ SRT å…§å®¹æ•´ç†æˆè©³ç´°é€å­—ç¨¿ï¼Œæ ¼å¼ç‚º [æ™‚é–“] ç™¼è¨€ï¼šå…§å®¹ï¼š\n\n{state['raw_srt']}"
    # ç¢ºä¿ invoke æœ‰æ‹¿åˆ°æ±è¥¿
    response = llm.invoke(prompt)
    print("é€å­—ç¨¿æ•´ç†å®Œæˆ")
    return {"minutes": response.content}

def summarizer_node(state: State):
    print("--- [Node 2-B] æ­£åœ¨æå–é‡é»æ‘˜è¦... ---")
    prompt = f"è«‹æ ¹æ“šä»¥ä¸‹å…§å®¹æå–é‡é»æ‘˜è¦ï¼š\n\n{state['raw_txt']}"
    response = llm.invoke(prompt)
    print("é‡é»æ‘˜è¦å®Œæˆ")
    return {"summary": response.content}

def writer_node(state: State):
    print("--- [Node 3] Writer æœ€çµ‚å½™æ•´ä¸­... ---")
    # é€™è£¡æœƒç­‰åˆ° 2-A å’Œ 2-B éƒ½å®Œæˆå¾Œæ‰åŸ·è¡Œ
    report = (
        f"ã€æœƒè­°é‡é»æ‘˜è¦ã€‘\n{state.get('summary', 'æ‘˜è¦ç”Ÿæˆå¤±æ•—')}\n\n"
        f"{'='*30}\n\n"
        f"ã€è©³ç´°é€å­—ç¨¿ã€‘\n{state.get('minutes', 'é€å­—ç¨¿ç”Ÿæˆå¤±æ•—')}"
    )
    return {"final_report": report}

workflow = StateGraph(State)

workflow.add_node("asr", asr_node)
workflow.add_node("minutes_taker", minutes_taker_node)
workflow.add_node("summarizer", summarizer_node)
workflow.add_node("writer", writer_node)

workflow.add_edge(START, "asr")
workflow.add_edge("asr", "minutes_taker")
workflow.add_edge("asr", "summarizer")
workflow.add_edge("minutes_taker", "writer")
workflow.add_edge("summarizer", "writer")

workflow.add_edge("writer", END)

app = workflow.compile()

if __name__ == "__main__":
    WAV_FILE = "./audio/Podcast_EP14.wav"
    
    if os.path.exists(WAV_FILE):
        print("ğŸš€ å·¥ä½œæµå•Ÿå‹•...")
        # ä½¿ç”¨ invoke åŸ·è¡Œï¼Œä¸¦æ¥æ”¶æœ€çµ‚ç‹€æ…‹
        final_output = app.invoke({"audio_path": WAV_FILE})
        
        print("\n" + "#"*50)
        print("âœ¨ ä»»å‹™å…¨æ•¸å®Œæˆï¼Œç”¢å‡ºå¦‚ä¸‹ï¼š")
        print("#"*50 + "\n")
        print(final_output["final_report"])
    else:
        print(f"âŒ æ‰¾ä¸åˆ°éŸ³æª”ï¼š{WAV_FILE}")
